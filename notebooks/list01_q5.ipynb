{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac2c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import preprocessing\n",
    "\n",
    "bodyfat = pd.read_csv(\"../data/bodyfat.csv\")\n",
    "X = bodyfat.drop(columns=[\"BodyFat\",\"Density\"])\n",
    "y = bodyfat[\"BodyFat\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 10)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "cv_fold = np.zeros(len(y_train)).astype(int)\n",
    "\n",
    "for i, (_, fold_indexes) in enumerate(kf.split(X_train)):\n",
    "    cv_fold[fold_indexes] = int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d849653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>62</td>\n",
       "      <td>167.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>35.5</td>\n",
       "      <td>97.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>98.5</td>\n",
       "      <td>56.6</td>\n",
       "      <td>38.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>31.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>42</td>\n",
       "      <td>244.25</td>\n",
       "      <td>76.00</td>\n",
       "      <td>41.8</td>\n",
       "      <td>115.2</td>\n",
       "      <td>113.7</td>\n",
       "      <td>112.4</td>\n",
       "      <td>68.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>37.1</td>\n",
       "      <td>31.2</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>40</td>\n",
       "      <td>133.50</td>\n",
       "      <td>67.50</td>\n",
       "      <td>33.6</td>\n",
       "      <td>88.2</td>\n",
       "      <td>73.7</td>\n",
       "      <td>88.5</td>\n",
       "      <td>53.3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>27.9</td>\n",
       "      <td>26.2</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>50</td>\n",
       "      <td>194.75</td>\n",
       "      <td>70.75</td>\n",
       "      <td>39.0</td>\n",
       "      <td>103.7</td>\n",
       "      <td>97.6</td>\n",
       "      <td>104.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>25.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>35</td>\n",
       "      <td>172.75</td>\n",
       "      <td>69.50</td>\n",
       "      <td>37.6</td>\n",
       "      <td>99.1</td>\n",
       "      <td>90.8</td>\n",
       "      <td>98.1</td>\n",
       "      <td>60.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>32.5</td>\n",
       "      <td>29.8</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  Knee  Ankle  \\\n",
       "70    62  167.50   71.50  35.5   97.6     91.5   98.5   56.6  38.6   22.4   \n",
       "191   42  244.25   76.00  41.8  115.2    113.7  112.4   68.5  45.0   25.5   \n",
       "46    40  133.50   67.50  33.6   88.2     73.7   88.5   53.3  34.5   22.5   \n",
       "213   50  194.75   70.75  39.0  103.7     97.6  104.2   60.0  40.9   25.5   \n",
       "169   35  172.75   69.50  37.6   99.1     90.8   98.1   60.1  39.1   23.4   \n",
       "\n",
       "     Biceps  Forearm  Wrist  \n",
       "70     31.5     27.3   18.6  \n",
       "191    37.1     31.2   19.9  \n",
       "46     27.9     26.2   17.3  \n",
       "213    32.7     30.0   19.0  \n",
       "169    32.5     29.8   17.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(201, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cv_fold:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 0, 0, 2, 3, 0, 3, 1, 4, 4, 0, 2, 2, 4, 2, 4, 4, 2, 3, 0, 0, 1,\n",
       "       3, 2, 1, 2, 1, 3, 3, 2, 4, 4, 2, 4, 3, 0, 3, 2, 1, 0, 4, 1, 2, 1,\n",
       "       3, 2, 0, 0, 2, 1, 3, 2, 0, 2, 4, 0, 1, 4, 1, 0, 1, 0, 4, 0, 4, 4,\n",
       "       1, 1, 1, 0, 1, 3, 1, 4, 3, 0, 0, 4, 0, 2, 1, 2, 2, 1, 2, 3, 4, 0,\n",
       "       4, 4, 1, 0, 4, 3, 3, 1, 3, 2, 0, 1, 4, 1, 0, 1, 3, 2, 3, 4, 3, 0,\n",
       "       1, 0, 2, 4, 2, 4, 0, 1, 3, 2, 1, 1, 4, 4, 1, 4, 4, 0, 2, 3, 2, 0,\n",
       "       2, 3, 3, 3, 0, 3, 2, 4, 4, 4, 0, 3, 1, 3, 3, 3, 2, 3, 3, 3, 3, 4,\n",
       "       0, 0, 4, 4, 4, 1, 0, 2, 1, 0, 4, 2, 3, 1, 1, 2, 1, 0, 1, 0, 3, 0,\n",
       "       1, 3, 2, 0, 2, 3, 4, 3, 4, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 0, 4, 1,\n",
       "       3, 3, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70     24.3\n",
       "191    38.1\n",
       "46     10.8\n",
       "213    18.7\n",
       "169    16.5\n",
       "Name: BodyFat, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(201,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('X_train:')\n",
    "display(X_train.head())\n",
    "display(X_train.shape)\n",
    "\n",
    "print('\\ncv_fold:')\n",
    "display(cv_fold)\n",
    "\n",
    "print('\\ny_train:')\n",
    "display(y_train.head())\n",
    "display(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a085ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train:np.ndarray, X_test:np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Normalize the training and testing data using StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train (np.ndarray): Training feature data.\n",
    "    - X_test (np.ndarray): Testing feature data.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple[np.ndarray, np.ndarray]: Normalized training and testing feature data.\n",
    "    \"\"\"\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1a7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_norm:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Neck</th>\n",
       "      <th>Chest</th>\n",
       "      <th>Abdomen</th>\n",
       "      <th>Hip</th>\n",
       "      <th>Thigh</th>\n",
       "      <th>Knee</th>\n",
       "      <th>Ankle</th>\n",
       "      <th>Biceps</th>\n",
       "      <th>Forearm</th>\n",
       "      <th>Wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.400681</td>\n",
       "      <td>-0.369547</td>\n",
       "      <td>0.386284</td>\n",
       "      <td>-1.005252</td>\n",
       "      <td>-0.373185</td>\n",
       "      <td>-0.092722</td>\n",
       "      <td>-0.203796</td>\n",
       "      <td>-0.542717</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>-0.378185</td>\n",
       "      <td>-0.269119</td>\n",
       "      <td>-0.682443</td>\n",
       "      <td>0.397447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.208561</td>\n",
       "      <td>2.184283</td>\n",
       "      <td>1.553849</td>\n",
       "      <td>1.558080</td>\n",
       "      <td>1.743507</td>\n",
       "      <td>1.977039</td>\n",
       "      <td>1.678470</td>\n",
       "      <td>1.656375</td>\n",
       "      <td>2.609490</td>\n",
       "      <td>1.333121</td>\n",
       "      <td>1.562323</td>\n",
       "      <td>1.241899</td>\n",
       "      <td>1.774807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.369485</td>\n",
       "      <td>-1.500886</td>\n",
       "      <td>-0.651552</td>\n",
       "      <td>-1.778320</td>\n",
       "      <td>-1.503691</td>\n",
       "      <td>-1.752260</td>\n",
       "      <td>-1.557945</td>\n",
       "      <td>-1.152549</td>\n",
       "      <td>-1.651499</td>\n",
       "      <td>-0.322981</td>\n",
       "      <td>-1.446475</td>\n",
       "      <td>-1.225207</td>\n",
       "      <td>-0.979913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.435136</td>\n",
       "      <td>0.537187</td>\n",
       "      <td>0.191690</td>\n",
       "      <td>0.418821</td>\n",
       "      <td>0.360441</td>\n",
       "      <td>0.475996</td>\n",
       "      <td>0.568069</td>\n",
       "      <td>0.085595</td>\n",
       "      <td>0.945675</td>\n",
       "      <td>1.333121</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.649794</td>\n",
       "      <td>0.821250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.771796</td>\n",
       "      <td>-0.194855</td>\n",
       "      <td>-0.132634</td>\n",
       "      <td>-0.150808</td>\n",
       "      <td>-0.192786</td>\n",
       "      <td>-0.157985</td>\n",
       "      <td>-0.257962</td>\n",
       "      <td>0.104075</td>\n",
       "      <td>0.215220</td>\n",
       "      <td>0.173850</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.551110</td>\n",
       "      <td>-0.873962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age    Weight    Height      Neck     Chest   Abdomen       Hip  \\\n",
       "0  1.400681 -0.369547  0.386284 -1.005252 -0.373185 -0.092722 -0.203796   \n",
       "1 -0.208561  2.184283  1.553849  1.558080  1.743507  1.977039  1.678470   \n",
       "2 -0.369485 -1.500886 -0.651552 -1.778320 -1.503691 -1.752260 -1.557945   \n",
       "3  0.435136  0.537187  0.191690  0.418821  0.360441  0.475996  0.568069   \n",
       "4 -0.771796 -0.194855 -0.132634 -0.150808 -0.192786 -0.157985 -0.257962   \n",
       "\n",
       "      Thigh      Knee     Ankle    Biceps   Forearm     Wrist  \n",
       "0 -0.542717  0.012316 -0.378185 -0.269119 -0.682443  0.397447  \n",
       "1  1.656375  2.609490  1.333121  1.562323  1.241899  1.774807  \n",
       "2 -1.152549 -1.651499 -0.322981 -1.446475 -1.225207 -0.979913  \n",
       "3  0.085595  0.945675  1.333121  0.123333  0.649794  0.821250  \n",
       "4  0.104075  0.215220  0.173850  0.057924  0.551110 -0.873962  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(201, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_train_norm, X_test_norm = normalize_data(X_train, X_test)\n",
    "print('X_train_norm:')\n",
    "display(pd.DataFrame(X_train_norm,columns=X_train.columns).head()   )\n",
    "display(X_train_norm.shape)\n",
    "print('Standard deviation:', np.std(X_train_norm, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ed9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def best_subset_selection(X_train:np.ndarray, Y_train:np.ndarray)-> dict:\n",
    "    \"\"\"\n",
    "    Perform best subset selection for linear regression. This function evaluates all possible combinations of features\n",
    "    and selects the best model for each subset size based on R-squared.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (np.ndarray): Training feature data. Shape (n_samples, n_features).\n",
    "    - Y_train (np.ndarray): Training target data. Shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where each key is the subset size (as a string) and the value is another dictionary containing:\n",
    "        - 'best_model': The statsmodels OLS regression results object for the best model.\n",
    "        - 'best_r2': The R-squared value of the best model.\n",
    "        - 'best_features': A tuple of feature indices used in the best model.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Useful dimensions\n",
    "    n, p = X_train.shape\n",
    "\n",
    "    # Initialize dictionary to store the best model for each subset size\n",
    "    best_model_k = {}\n",
    "    \n",
    "    # Create model for no feature\n",
    "    best_model_k['0'] = {}\n",
    "    best_model_k['0']['best_model'] = sm.OLS(Y_train, np.ones((len(Y_train),1))).fit()\n",
    "    best_model_k['0']['best_r2'] = best_model_k['0']['best_model'].rsquared\n",
    "    best_model_k['0']['best_features'] = []\n",
    "\n",
    "    for k in range(1, p+1):\n",
    "        best_r2 = 0\n",
    "        best_features = [] \n",
    "        best_model = []\n",
    "        \n",
    "        # Create every model with k features (excluding intercept)\n",
    "        for feature_combination in itertools.combinations(range(p), k):\n",
    "            X_train_aux  = sm.add_constant(X_train[:,feature_combination])\n",
    "            model = sm.OLS(Y_train, X_train_aux).fit()\n",
    "            if model.rsquared > best_r2:\n",
    "                best_r2 = model.rsquared\n",
    "                best_model = model\n",
    "                best_features = feature_combination\n",
    "\n",
    "        # Store the best model for this subset size\n",
    "        best_model_k[str(k)] = {\n",
    "            'best_model': best_model,\n",
    "            'best_r2': best_r2,\n",
    "            'best_features': best_features\n",
    "        }\n",
    "\n",
    "    return best_model_k\n",
    "            \n",
    "#best_models = best_subset_selection(X_train.values, y_train.values)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7437f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foward_stepwise_selection(X_train:np.ndarray, Y_train:np.ndarray)-> dict:\n",
    "    \"\"\"\n",
    "    Function to perform forward stepwise selection for linear regression. This function iteratively adds features\n",
    "    to the model and selects the best model for each subset size based on R-squared. Only one feature is added at each step.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (np.ndarray): Training feature data. Shape (n_samples, n_features).\n",
    "    - Y_train (np.ndarray): Training target data. Shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where each key is the subset size (as a string) and the value is another dictionary containing:\n",
    "        - 'best_model': The statsmodels OLS regression results object for the best model.\n",
    "        - 'best_r2': The R-squared value of the best model.\n",
    "        - 'best_features': A tuple of feature indices used in the best model.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Useful dimensions\n",
    "    n, p = X_train.shape\n",
    "\n",
    "    # Initialize dictionary to store the best model for each subset size\n",
    "    best_model_k = {}\n",
    "    \n",
    "    # Create model for no feature\n",
    "    best_model_k['0'] = {}\n",
    "    best_model_k['0']['best_model'] = sm.OLS(Y_train, np.ones((len(Y_train),1))).fit()\n",
    "    best_model_k['0']['best_r2'] = best_model_k['0']['best_model'].rsquared\n",
    "    best_model_k['0']['best_features'] = []\n",
    "\n",
    "    remaining_features = list(range(p))\n",
    "    current_features = []\n",
    "\n",
    "    for k in range(1, p+1):\n",
    "        best_r2 = 0\n",
    "        best_feature = [] \n",
    "        best_model = []\n",
    "        # Create every model with k features (excluding intercept)\n",
    "        for feature_combination in itertools.combinations(remaining_features, 1):\n",
    "            #import pdb; pdb.set_trace()\n",
    "            feature_combination_list = list(feature_combination)  # Convert tuple to list\n",
    "            X_train_aux  = sm.add_constant(X_train[:,feature_combination_list + current_features])\n",
    "            model = sm.OLS(Y_train, X_train_aux).fit()\n",
    "            if model.rsquared > best_r2:\n",
    "                best_r2 = model.rsquared\n",
    "                best_model = model\n",
    "                best_feature = feature_combination_list[0]\n",
    "\n",
    "        # Move best feature for k from the remainig_features list to current_features\n",
    "        remaining_features.remove(best_feature)\n",
    "        current_features.append(best_feature)\n",
    "\n",
    "        # Store the best model for this subset size\n",
    "        best_model_k[str(k)] = {\n",
    "            'best_model': best_model,\n",
    "            'best_r2': best_r2,\n",
    "            'best_features': current_features.copy()\n",
    "        }\n",
    "\n",
    "    return best_model_k\n",
    "\n",
    "best_models_pl = foward_stepwise_selection(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72043f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bd7fb0>,\n",
       "  'best_r2': np.float64(0.0),\n",
       "  'best_features': []},\n",
       " '1': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf89b0>,\n",
       "  'best_r2': np.float64(0.6404157973526722),\n",
       "  'best_features': [5]},\n",
       " '2': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf8c50>,\n",
       "  'best_r2': np.float64(0.693716876511187),\n",
       "  'best_features': [5, 1]},\n",
       " '3': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf8e30>,\n",
       "  'best_r2': np.float64(0.7100124087139326),\n",
       "  'best_features': [5, 1, 12]},\n",
       " '4': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf8f50>,\n",
       "  'best_r2': np.float64(0.7192801308495235),\n",
       "  'best_features': [5, 1, 12, 10]},\n",
       " '5': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf9a30>,\n",
       "  'best_r2': np.float64(0.7231554582194162),\n",
       "  'best_features': [5, 1, 12, 10, 11]},\n",
       " '6': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf9d90>,\n",
       "  'best_r2': np.float64(0.7263015578363179),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3]},\n",
       " '7': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf9f10>,\n",
       "  'best_r2': np.float64(0.7286154367274877),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7]},\n",
       " '8': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf92b0>,\n",
       "  'best_r2': np.float64(0.7316170437252492),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7, 0]},\n",
       " '9': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bf87d0>,\n",
       "  'best_r2': np.float64(0.7336884885165282),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7, 0, 6]},\n",
       " '10': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bfab10>,\n",
       "  'best_r2': np.float64(0.7348072970162933),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7, 0, 6, 9]},\n",
       " '11': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bfa390>,\n",
       "  'best_r2': np.float64(0.735076289045421),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7, 0, 6, 9, 4]},\n",
       " '12': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bfaed0>,\n",
       "  'best_r2': np.float64(0.7353078015250751),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7, 0, 6, 9, 4, 2]},\n",
       " '13': {'best_model': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1f877bfb290>,\n",
       "  'best_r2': np.float64(0.7354234718482391),\n",
       "  'best_features': [5, 1, 12, 10, 11, 3, 7, 0, 6, 9, 4, 2, 8]}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lasso_regression_cv(X: np.ndarray, y: np.ndarray, cv_fold: np.ndarray, alphas: list[float]) -> dict:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c42ef",
   "metadata": {},
   "source": [
    "## b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_impa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
